# models/head.py — REPLACE ENTIRE FILE
from __future__ import annotations
from dataclasses import dataclass
from typing import Dict, List, Optional, Any
import numpy as np
from sklearn.linear_model import LogisticRegression, Ridge  # ✅ ADDED Ridge

@dataclass
class TrainedModel:
    label_names: List[str]
    task_types: Dict[str, str]
    models: Dict[str, Optional[Any]]
    scaler_mean: np.ndarray
    scaler_std: np.ndarray
    default_value: Dict[str, float]

def standardize_fit(X: np.ndarray):
    mean = X.mean(axis=0)
    std = X.std(axis=0) + 1e-8
    return mean, std

def standardize_apply(X: np.ndarray, mean: np.ndarray, std: np.ndarray):
    return (X - mean) / std

def train_logreg_multitask(
    X: np.ndarray,
    Y: np.ndarray,
    M: np.ndarray,
    label_names: List[str],
    task_types: Dict[str, str],
    max_iter: int = 2000,
    min_n: int = 10,
) -> TrainedModel:
    mean, std = standardize_fit(X)
    Xs = standardize_apply(X, mean, std)

    models: Dict[str, Optional[Any]] = {}
    default_value: Dict[str, float] = {}

    for j, name in enumerate(label_names):
        valid = M[:, j] > 0.5
        n_valid = int(valid.sum())
        if n_valid < min_n:
            models[name] = None
            default_value[name] = 0.5 if task_types.get(name, "classification") == "classification" else 0.0
            continue

        yj = Y[valid, j]
        xj = Xs[valid]
        task_type = task_types.get(name, "classification")

        # Skip single-value tasks
        uniq = np.unique(np.round(yj, 6)) if task_type == "regression" else np.unique(yj.astype(int))
        if uniq.size < 2:
            models[name] = None
            default_value[name] = float(yj.mean()) if yj.size else (0.5 if task_type == "classification" else 0.0)
            continue

        # ✅ TRAIN CORRECT MODEL PER TASK TYPE
        if task_type == "regression":
            model = Ridge(alpha=1.0, max_iter=max_iter)  # ✅ REGRESSION
            model.fit(xj, yj)
        else:
            model = LogisticRegression(max_iter=max_iter, n_jobs=-1)  # Classification
            model.fit(xj, yj.astype(int))
        
        models[name] = model
        default_value[name] = float(yj.mean())

    return TrainedModel(
        label_names=label_names,
        task_types=task_types,
        models=models,
        scaler_mean=mean,
        scaler_std=std,
        default_value=default_value,
    )

def predict_proba(model: TrainedModel, X: np.ndarray) -> np.ndarray:
    """Returns raw predictions for regression, probabilities for classification."""
    Xs = standardize_apply(X, model.scaler_mean, model.scaler_std)
    N = X.shape[0]
    T = len(model.label_names)
    prob = np.zeros((N, T), dtype=np.float32)

    for j, name in enumerate(model.label_names):
        m = model.models.get(name)
        task_type = model.task_types.get(name, "classification")
        if m is None:
            prob[:, j] = np.float32(model.default_value.get(name, 0.5))
            continue
        if task_type == "regression":
            prob[:, j] = m.predict(Xs).astype(np.float32)  # ✅ RAW PREDICTION
        else:
            prob[:, j] = m.predict_proba(Xs)[:, 1].astype(np.float32)
    return prob

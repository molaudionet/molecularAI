# ESOL Dataset - Fusion Mode (Descriptors + Audio)
# Aqueous Solubility Prediction (Regression)
# Multi-modal: RDKit descriptors + Molecular sonification

run:
  seed: 42
  split:
    train: 0.8
    val: 0.1
    test: 0.1

train_mode: "fusion"

dataset:
  path: "data/esol.csv"
  smiles_col: "smiles"
  id_col: "Compound ID"
  label_cols:
    - "measured log solubility in mols per litre"
  
  # Task type: regression for solubility prediction
  task_types:
    "measured log solubility in mols per litre": "regression"

features:
  mode: "fusion"
  cache_dir: "cache/esol_fuse"
  
  audio:
    enabled: true
    
    # Audio generation parameters
    generation:
      sample_rate: 16000
      duration: 2.0
      frequency_range: [20, 20000]
      mapping_method: "property_based"  # Maps atomic properties to frequencies
    
    # Wav2Vec 2.0 embedding extraction
    embed:
      model_name: "facebook/wav2vec2-base"
      cache_path: "cache/esol_fuse/audio_embeddings.npy"
      layer: -1  # Use last layer
      pooling: "mean"  # Mean pooling over time

model:
  type: "mlp"
  # Larger network for combined features (7 descriptors + 768 audio = 775 features)
  hidden_dims: [512, 256, 128, 64]
  dropout: 0.3
  batch_norm: true

train:
  epochs: 100
  batch_size: 32
  lr: 0.001
  optimizer: "adam"
  weight_decay: 0.0001
  
  early_stopping:
    enabled: true
    patience: 20
    metric: "val_loss"
    mode: "min"
  
  scheduler:
    enabled: true
    type: "reduce_on_plateau"
    patience: 10
    factor: 0.5
    min_lr: 0.00001

# Regression metrics
metrics:
  primary: "r2"
  additional: ["rmse", "mae"]
